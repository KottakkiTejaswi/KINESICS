# KINESICS
"Communication is not only a flow of words rather a body language."

## Inspiration
One of the most important part of communication is hearing what isn't said. Our body language tells a lot about us. Body language and nonverbal communication can reveal a lot about a person's thoughts and feelings. Our genes are wired to interpret basic communication gestures, such as smiling or frowning. However, cultural differences can affect the interpretation of nonverbal cues, making it important to understand these differences.

The Body Language Decoder is a tool that helps users decode nonverbal communication and understand the wealth of meaning in the body language of those around them. By providing insights into specific gestures and their cultural context, the Body Language Decoder empowers users to understand others better and express themselves more effectively. Whether it's in personal or professional relationships, decoding nonverbal communication can lead to more successful interactions and better outcomes.

We named our project as Kinesics as it refers to the study of body language and nonverbal communication, including gestures, facial expressions, eye contact, posture, and other physical movements. It involves the analysis of how these nonverbal cues are used to convey meaning in communication, and how they can be interpreted to better understand the emotions, attitudes, and intentions of others. Kinesics is a multidisciplinary field that draws on psychology, sociology, anthropology, linguistics, and other related areas of study to explore the ways in which nonverbal communication is used to convey meaning in human interactions.

## What it does
This project is designed to detect and track facial expressions and body movements, using computer vision techniques and machine learning algorithms to interpret the person's behavior and determine their current emotional state.

## How we built it
To build this tool, we utilized Mediapipe, which enabled us to estimate facial and body landmarks in real-time. With the data obtained from Mediapipe, we developed custom pose classification models that help us to interpret a person's body language and determine what they might be communicating non-verbally. By combining the power of computer vision and machine learning, we were able to create a robust solution that can decode the complex nuances of nonverbal communication.

## Challenges we ran into
One of the main challenges we faced was achieving the highest possible accuracy in predicting emotions.

## Accomplishments that we're proud of
We're proud to have achieved our goal of detecting facial outlines, body pose, and accurately predicting emotions. Developing this tool in just one night was a significant accomplishment, especially since we are relatively new to the field. We learned a lot throughout the process and were able to apply our knowledge of computer vision and machine learning to create a functional and effective solution.

## What we learned
Through this project, we gained valuable insights into how we can customize and communicate our body language using features provided by Mediapipe. We also deepened our understanding of computer vision and machine learning techniques, and learned how to apply these concepts to real-world problems. Overall, this experience helped us to enhance our skills and knowledge in this exciting field.

## What's next for KINESICS
Kinesics could be used to develop software that assists individuals in enhancing their communication skills. By analyzing body language and facial expressions during interactions, the software could provide feedback on how to improve communication and build rapport with others. We believe that Kinesics has great potential to help individuals in various fields and are excited to continue developing it further.
